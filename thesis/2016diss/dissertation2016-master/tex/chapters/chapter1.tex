\chapter{Introduction}\label{chapter1}

The use of language has been a fundamental part of human interaction since our earliest ancestors. The fluency and frequency of speech became an integral part of society for millennium. With the advent of low cost computer systems and large scale networks, humans have come to expect the same immediacy of face-to-face spoken language with any other communication medium. The rise of the internet is proof of the innate need for humans to communicate. Due to the increased presence of computational systems in daily life, this immediacy of communication and understanding has transferred by proxy to our technological counterparts. We now expect our devices to communicate in the same manner as our fellow humans.

The task of creating a system which understands human speech and can communicate in a meaningful way has become a broad and evolving field. Understanding semantics of natural language and creating useful models is an integral part in the process of understanding human language. The syntax of human language gives us information about structure which is usually tightly coupled with semantics. The structure of a human language is assumed to contain useful semantic content. Therefore, using syntactic structure and semantic concepts, we can create models which contain form and meaning. 

Formulating the task using syntactic Part-Of-Speech (POS) tags and Semantic supersenses, we can create a more rich structure which contains semantic information. Like most natural language systems, context is important and detection and disambiguation of semantic units is key to understanding a broader semantic context. The task that is proposed is to detect minimal semantic units in a given a POS tagged sentence and produce a semantically supersense tagged sentence.

Using a sentence with semantic embeddings can help disambiguate broader concepts in a discourse domain, or simply be used for answering simple questions. Therefore, detecting meaningful semantic units is an important building block to creating a system which has the capability to understand human language. The more accurate the results in a semantic context, the more communicative a broad scale linguistic system can become.

\section{Aims}

The goal of detecting minimal semantic units is to create a system which can train with POS tagged sentences as an input and produce Supersense tagged sentences as a predicted output. During this process, disambiguation of Multiword expressions should occur as well as Named Entities.
The objective is to be able to predict after adequate pre-processing and training.

\section{Objectives}

The original shared task is defined and outlined in SemEval 2016 Task 10 \cite{dimsum16web}: Detecting Minimal Semantic Units and their Meaning (\dimsum). The task requires using supervised or semi-supervised learning methodologies to recognise Multiword expressions given syntactic context, and tagging them along with other words with supersenses as lexical semantic entities. The training input is a POS tagged sentence and the predicted output is a supersense tagged sentence.

\begin{table}[!htbp]
\small
\centering
  \begin{framed}
  \begin{tabular}{lllllllll} 
    I    & googled & restaurants & in  & the & area & and  & Fuji  & Sushi\\
    {\bf PRON} & {\bf VERB}    & {\bf NOUN}        & {\bf ADP} & {\bf DET} & {\bf NOUN} & {\bf CONJ} & {\bf PRPN} & {\bf PRPN}\\
    & \\
    came & up  & and  & reviews & were & great & so  & I    & made\\
    {\bf VERB} & {\bf ADV} & {\bf CONJ} & {\bf NOUN}    & {\bf VERB} & {\bf ADJ}   & {\bf ADV} & {\bf PRON} & {\bf VERB}\\
    & \\
    a & carry & out & order & & & & & \\
    {\bf DET} & {\bf VERB} & {\bf ADP} & {\bf NOUN} & & & & &
  \end{tabular}
  \end{framed}
  \caption{Example DiMSUM Training entry: A POS Tagged Sentence}
  \label{tab:dimsumtraininput}
\end{table}

\begin{table}[!htbp]
\small
\centering
  \begin{framed}
  \begin{tabular}{ lllll }
    I & googled         & restaurants & in & the \\
    \ & {\it v.communication} & {\it n.group}       &    &     \\
    & \\
    area       & and & Fuji\_Sushi & came\_up        & and \\
    {\it n.location} &     & {\it n.group}     & {\it v.communication }&     \\
    & \\
    reviews         & were      & great & so & I \\
    {\it n.communication} & {\it v.stative} &       &    &   \\ 
    & \\
    made\_ & a & carry\_out  & \_order         & \\
    \      &   & {\it v.possession} & {\it v.communication} &
  \end{tabular}
  \end{framed}
  \caption{Example \dimsum Predicted entry: A Supersense Tagged Sentence}
  \label{tab:dimsumpredoutput}
\end{table}

Table \ref{tab:dimsumtraininput} is an example of a POS tagged sentence that would be used to train a supervised or semi-supervised learning system while Table \ref{tab:dimsumpredoutput} is an example prediction of a Supersense tagged sentence given the previous tagged sentence as an input.

As specified by the task website \cite{dimsum16web}, ``Noun supersenses start with n., verb supersenses with v., and \_ joins tokens within a multiword expression.''\footnote{$carry\_out_{v.possession}$ and $made\_order_{v.communication}$ are separate MWEs.}

Learning a word or multiword expression with a specific supersenses will be difficult, which entails sparse data for semantic context in MWEs and supersense pairs globally. Pairing contextual word senses will be used to focus scope and produce a highly coupled contextual result.

The \dimsum task can be thought of as a cross between Word Sense Disambiguation (WSD) tasks and syntactically complex Named Entity Recognition (NER). In WSD tasks, a semantic sense should be chosen for a given word, and in NER tasks, traditionally boundary labels are predicted in a contiguous manner. The \dimsum task does both, but with the added complexity of allowing for non-contiguous ``gaps'' in boundaries in Multiword Expressions (MWE) paired with Supersense labelling.
Initial work did not allow for syntactic flexibility such as work by \cite{Katz2006}, \cite{Constant2011}, leading to additional studies with more gappy constructions such as \cite{cook2007pulling} and \cite{Schneider2014} finally creating more robust datasets to capture long range complex syntactic dependencies (\cite{Schneider2014a}, \cite{Schneider2015a}).
Creating an elegant general solution for recognising Multiword Expressions and assigning Supersenses creates a framework to recognise Named Entities and long range multiword dependencies such as Idioms and Phrasal Verbs. Computer systems can then assign useful semantic meta-data allowing for enhancements across fields such as Information Retrieval, Machine Translation, Information Extraction, Question Answering systems and much more. 

In Chapter \ref{chapter2}, The literature review of the task and its corresponding subjects are covered. Introductions to topics and studies related to such topics will be critiqued. Historical literature on WordNet, Multiword expressions, Named entity recognition, Semantic supersenses and other semantic definitions will be introduced and clarified in the context of the task, as well as additional models for classification.
Following the literature review, in Chapter \ref{chapter3} we cover the requirements and analysis of the project. It will speak about data requirements and organisation, with special attention to prediction of data labels. It will move on to analysis of said data and finish with analysis on solution design.
With the knowledge of the requirements and analysis, Chapter \ref{chapter4} outlines a detailed description of the design of the CRF baseline(s) and final Bi-LSTM-CRF solution. 
Chapter \ref{chapter5} will cover results and discuss critically their meaning in regards to the \dimsum task. It will cover potential issues and further research derived from the critique.
Finally, Chapter \ref{chapter6} discusses overall conclusions about results, data, models and research.
